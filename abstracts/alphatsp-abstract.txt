Existing heuristic methods for solving combinatorial optimization problems generally perform and scale well, but rely on human intuition and decision making. Deep learning presents an opportunity to both automate the heuristic development process and learn policies that perform better than manuallys pecified strategies. AlphaTSP is a method inspired by AlphaZero for solving the Traveling Salesman Problem (TSP) that uses self-play reinforcement learning to learn a policy network to guide Monte Carlo tree search (MCTS). MCTS acts as an improvement operator to find a posterior policy given the policy of a neural network, which can be used as training for the network. A specialized graph neural network and graph construction approach are developed as a strong policy network. We demonstrate that AlphaTSP performs better than nearest neighbor and plain MCTS for solving small TSP instances on random Euclidean points, but is more computationally intensive.